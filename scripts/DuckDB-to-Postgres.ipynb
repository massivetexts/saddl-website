{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q psycopg2 # library for postrgres connector\n",
                "from sqlalchemy import create_engine\n",
                "import pandas as pd\n",
                "import duckdb\n",
                "duckcon = duckdb.connect()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# connect to engine. This assumes a DB name of saddl, and root user without a pw\n",
                "engine = create_engine('postgresql://:@localhost:5432/saddl')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CREATE TABLE meta(htid VARCHAR, \"access\" VARCHAR, rights VARCHAR, ht_bib_key VARCHAR, description VARCHAR, source VARCHAR, source_bib_num VARCHAR, oclc_num VARCHAR, isbn VARCHAR, issn VARCHAR, lccn VARCHAR, title VARCHAR, imprint VARCHAR, rights_reason_code VARCHAR, rights_timestamp VARCHAR, us_gov_doc_flag INT, rights_date_used REAL, pub_place VARCHAR, lang VARCHAR, bib_fmt VARCHAR, collection_code VARCHAR, content_provider_code VARCHAR, responsible_entity_code VARCHAR, digitization_agent_code VARCHAR, access_profile_code VARCHAR, author VARCHAR, page_count VARCHAR);\n",
                        "CREATE TABLE clean_predictions(target VARCHAR, candidate VARCHAR, swsm REAL, swde REAL, wp_dv REAL, partof REAL, contains REAL, \"OVERLAPS\" REAL, author REAL, simdiff REAL, grsim REAL, randdiff REAL, relatedness REAL, count INTEGER);\n",
                        "CREATE TABLE work_predictions(target INT, candidate INT, swsm REAL, swde REAL, wp_dv REAL, partof REAL, contains REAL, \"overlaps\" REAL, author REAL, simdiff REAL, grsim REAL, randdiff REAL, count INTEGER);\n",
                        "CREATE TABLE manifestation_stats(man_id INT, label_count INT, gov_count INT, serial_count INT, gov_prop REAL, serial_prop REAL, include BOOLEAN, best_centroid VARCHAR, best_centroid_pd VARCHAR, best_median VARCHAR, best_median_pd VARCHAR);\n",
                        "CREATE TABLE work_stats(work_id INT, label_count INT, gov_count INT, serial_count INT, gov_prop REAL, serial_prop REAL, include BOOLEAN, best_centroid VARCHAR, best_centroid_pd VARCHAR, best_median VARCHAR, best_median_pd VARCHAR);\n",
                        "CREATE TABLE manifestation_predictions(target INT, candidate INT, swsm REAL, swde REAL, wp_dv REAL, partof REAL, contains REAL, \"overlaps\" REAL, author REAL, simdiff REAL, grsim REAL, randdiff REAL, count INTEGER);\n",
                        "CREATE TABLE clusters(htid VARCHAR, work_id INT, man_id INT);\n"
                    ]
                }
            ],
            "source": [
                "with engine.connect() as con:\n",
                "    with open('../db-export/0-0-1-prerelease/schema.sql', mode='r') as f:\n",
                "        cmds = []\n",
                "        for line in f.readlines():\n",
                "            if 'CREATE TABLE' in line:\n",
                "                line = line.strip().replace('BIGINT', 'INT').replace('FLOAT', 'REAL').replace('DOUBLE', 'REAL')\n",
                "                print(line)\n",
                "                con.execute(line.split('(')[0].replace('CREATE TABLE', 'DROP TABLE IF EXISTS'))\n",
                "                result = con.execute(line)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'csv_tmp_path' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[0;32m/var/folders/sv/k_t1xdpj7_s7zdj34_47mdy40000gp/T/ipykernel_18782/3740291221.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mduckcon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"SELECT * FROM '{csv_tmp_path}' LIMIT 1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m: name 'csv_tmp_path' is not defined"
                    ]
                }
            ],
            "source": [
                "duckcon.execute(f\"SELECT * FROM '{csv_tmp_path}' LIMIT 1\").fetch_df()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Paths in load.sql should correctly point to the DB export and be absolute."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "THIS COPY CMD doesn't run from Python's SQL connector, copy and run it in the command line.\n",
                        "========================================\n",
                        "COPY clusters FROM '/Users/organisciak/Documents/projects/saddl-website/db-export/0-0-1-prerelease/7_clusters.csv' DELIMITER ',' CSV HEADER;\n",
                        "COPY clean_predictions FROM '/Users/organisciak/Documents/projects/saddl-website/db-export/0-0-1-prerelease/1_clean_predictions.csv' DELIMITER ',' CSV HEADER;\n",
                        "COPY work_predictions FROM '/Users/organisciak/Documents/projects/saddl-website/db-export/0-0-1-prerelease/2_work_predictions.csv' DELIMITER ',' CSV HEADER;\n",
                        "COPY meta FROM '/Users/organisciak/Documents/projects/saddl-website/db-export/0-0-1-prerelease/0_meta.csv' DELIMITER ',' CSV HEADER;\n",
                        "COPY manifestation_predictions FROM '/Users/organisciak/Documents/projects/saddl-website/db-export/0-0-1-prerelease/6_manifestation_predictions.csv' DELIMITER ',' CSV HEADER;\n",
                        "COPY manifestation_stats FROM '/Users/organisciak/Documents/projects/saddl-website/db-export/0-0-1-prerelease/3_manifestation_stats.csv' DELIMITER ',' CSV HEADER;\n",
                        "COPY work_stats FROM '/Users/organisciak/Documents/projects/saddl-website/db-export/0-0-1-prerelease/4_work_stats.csv' DELIMITER ',' CSV HEADER;\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import time\n",
                "with engine.connect() as con:\n",
                "    with open('../db-export/0-0-1-prerelease/load.sql', mode='r') as f:\n",
                "        copy_cmds = []\n",
                "        print(\"THIS COPY CMD doesn't run from Python's SQL connector, copy and run it in the command line.\")\n",
                "        print(\"=\"*40)\n",
                "        for copy_cmd in f.readlines():\n",
                "            if 'COPY' not in copy_cmd:\n",
                "                continue\n",
                "            a, b = copy_cmd.split(' FROM \\'')\n",
                "            _, table_name = a.split()\n",
                "            parquet_location = b.split(\"' (FORMAT\")[0].strip(\"'\")\n",
                "            csv_tmp_path = parquet_location.replace('parquet', 'csv')\n",
                "            #pd.read_parquet(parquet_location).to_csv(csv_tmp_path, index=False, header=True)\n",
                "            # use duckdb instead\n",
                "            duckcon.execute(f\"COPY '{parquet_location}' TO '{csv_tmp_path}' WITH ( DELIMITER ',', HEADER 1);\")\n",
                "            pq_cmd = f\"COPY {table_name} FROM '{csv_tmp_path}' DELIMITER ',' CSV HEADER;\"\n",
                "            print(pq_cmd)\n",
                "            #con.execute(pq_cmd)\n",
                "            #os.remove(csv_tmp_path)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "if you have users with privileges granted to the tables that you just dropped and recreated, you need to run this\n",
                "```sql\n",
                "GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO saddl;\n",
                "GRANT ALL PRIVILEGES ON ALL SEQUENCES IN SCHEMA public TO saddl;\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ADD PRIMARY KEY\n",
                "\n",
                "`ALTER TABLE` locks the table, so make sure there's nothing else blocking your query.\n",
                "\n",
                "https://stackoverflow.com/questions/26489244/how-to-detect-query-which-holds-the-lock-in-postgres\n",
                "\n",
                "https://stackoverflow.com/questions/35319597/how-to-stop-kill-a-query-in-postgresql"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "with engine.connect() as con:\n",
                "    con.execute('ALTER TABLE work_stats ADD PRIMARY KEY (work_id);')\n",
                "    con.execute('ALTER TABLE manifestation_stats ADD PRIMARY KEY (man_id);')\n",
                "    con.execute('ALTER TABLE meta ADD PRIMARY KEY (htid);')\n",
                "    con.execute('ALTER TABLE clusters ADD PRIMARY KEY (htid);')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## CREATE INDEX\n",
                "\n",
                "This makes a huge difference."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "with engine.connect() as con:\n",
                "    con.execute('CREATE INDEX target_idx ON clean_predictions (target);')\n",
                "    con.execute('CREATE INDEX candidate_idx ON clean_predictions (candidate);')\n",
                "\n",
                "    con.execute('CREATE INDEX target_work_idx ON work_predictions (target);')\n",
                "    con.execute('CREATE INDEX candidate_work_idx ON work_predictions (candidate);')\n",
                "\n",
                "    con.execute('CREATE INDEX target_man_idx ON manifestation_predictions (target);')\n",
                "    con.execute('CREATE INDEX candidate_man_idx ON manifestation_predictions (candidate);')\n",
                "\n",
                "    con.execute('CREATE INDEX work_cluster_idx ON clusters (work_id);')\n",
                "    con.execute('CREATE INDEX man_cluster_idx ON clusters (man_id);')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Create Search vector column and index\n",
                "\n",
                "Currently, this is just title and author concatenated. Can be improved with weighting or field-specific search, or text highlighting.\n",
                "https://www.postgresql.org/docs/9.5/textsearch-tables.html.\n",
                "\n",
                "Some notes:\n",
                "- `coalesce(title, '')` ensures that fields are still concatenated when NULL."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "with engine.connect() as con:\n",
                "    con.execute('ALTER TABLE meta ADD COLUMN textsearch tsvector;')\n",
                "    con.execute('''UPDATE meta SET textsearch =\n",
                "     to_tsvector('english', coalesce(title,'') || ' ' || coalesce(author,''));\n",
                "    ''')\n",
                "    con.execute('CREATE INDEX meta_search_idx ON meta USING GIN (textsearch);')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Test"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[(730141, 1, 0, 0, 0.0, 0.0, True, None, None, None, None)]"
                        ]
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "with engine.connect() as con:\n",
                "    result = con.execute('SELECT * FROM work_stats LIMIT 1')\n",
                "result.all()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>work_id</th>\n",
                            "      <th>label_count</th>\n",
                            "      <th>gov_count</th>\n",
                            "      <th>serial_count</th>\n",
                            "      <th>gov_prop</th>\n",
                            "      <th>serial_prop</th>\n",
                            "      <th>include</th>\n",
                            "      <th>best_centroid</th>\n",
                            "      <th>best_centroid_pd</th>\n",
                            "      <th>best_median</th>\n",
                            "      <th>best_median_pd</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>730141</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>True</td>\n",
                            "      <td>None</td>\n",
                            "      <td>None</td>\n",
                            "      <td>None</td>\n",
                            "      <td>None</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   work_id  label_count  gov_count  serial_count  gov_prop  serial_prop  \\\n",
                            "0   730141            1          0             0       0.0          0.0   \n",
                            "\n",
                            "   include best_centroid best_centroid_pd best_median best_median_pd  \n",
                            "0     True          None             None        None           None  "
                        ]
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "pd.read_sql('SELECT * FROM work_stats LIMIT 1', engine)"
            ]
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "379ed9c0df61780843c458600fb18608a0fc28d3616d16e8a179314cb2128fd7"
        },
        "kernelspec": {
            "display_name": "Python 3.8.8 64-bit ('base': conda)",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.8"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
